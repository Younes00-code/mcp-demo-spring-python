spring.application.name=mcp-client
spring.ai.mcp.client.type=sync

# Tu utilises Ollama sur localhost:11434 (comme tu l'as lancé via `ollama run tinyllama`)
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=tinyllama

server.port=8066
# Logging minimal (juste les erreurs)
logging.level.root=ERROR
server.error.include-stacktrace=never
spring.main.log-startup-info=false
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n
